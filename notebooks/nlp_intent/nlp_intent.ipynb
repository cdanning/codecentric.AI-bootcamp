{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# NLP Intent Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Hallo und herzlich willkommen zum codecentric.AI bootcamp!\n",
    "\n",
    "Heute wollen wir uns mit einem fortgeschrittenen Thema aus dem Bereich _natural language processing_, kurz _NLP_, genannt, beschäftigen:\n",
    "\n",
    "> Wie bringt man Sprachassistenten, Chatbots und ähnlichen Systemen bei, die Absicht eines Nutzers aus seinen Äußerungen zu erkennen?\n",
    "\n",
    "Dieses Problem wird im Englischen allgemein als _intent recognition_ bezeichnet und gehört zu dem ambitionierten Gebiet des _natural language understanding_, kurz _NLU_ genannt. Einen Einstieg in dieses Thema bietet das folgende [Youtube-Video](https://www.youtube.com/watch?v=H_3R8inCOvM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# lade Video\n",
    "from IPython.display import IFrame    \n",
    "IFrame('https://www.youtube.com/embed/H_3R8inCOvM', width=850, height=650)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Zusammen werden wir in diesem Tutorial mit Hilfe der NLU-Bibliothek [Rasa-NLU](https://rasa.com/docs/nlu/) einem WetterBot beibringen, einfache Fragemuster zum Wetter zu verstehen und zu beantworten. Zum Beispiel wird er auf die Fragen\n",
    "\n",
    "> `\"Wie warm war es 1989?\"`\n",
    "\n",
    "mit\n",
    "\n",
    "> <img src=\"img/answer-1.svg\" width=\"75%\" align=\"middle\">\n",
    "\n",
    "und auf\n",
    "\n",
    "> `\"Welche Temperatur hatten wir in Schleswig-Holstein und in Baden-Württemberg?\"`\n",
    "\n",
    "mit\n",
    "\n",
    ">  <img src=\"img/answer-2.svg\" width=\"75%\" align=\"middle\">\n",
    "\n",
    "antworten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Damit es gleich richtig losgehen kann, importieren wir noch zwei Standardbibliotheken und vereinbaren das Datenverzeichnis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DATA_DIR = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Unser Ausgangspunkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Allgemein ist die Aufgabe, aus einer Sprachäußerung die zugrunde liegende Absicht zu erkennen, selbst für Menschen manchmal nicht einfach. Soll ein Computer diese schwierige Aufgabe lösen, so muss man sich überlegen, was man zu einem gegebenen Input &mdash; also einer (unstrukturierten) Sprachäußerung &mdash; für einen Output erwarten, wie man also Absichten modelliert und strukturiert.\n",
    "\n",
    "Weit verbreitet ist folgender Ansatz für Intent Recognition:\n",
    "\n",
    "- jede Äußerung wird einer _Domain_, also einem Gebiet, zugeordnet,\n",
    "- für jede _Domain_ gibt es einen festen Satz von _Intents_, also eine Reihe von Absichten,\n",
    "- jede Absicht kann durch _Parameter_ konkretisiert werden und hat dafür eine Reihe von _Slots_, die wie Parameter einer Funktion oder Felder eines Formulares mit gewissen Werten gefüllt werden können.\n",
    "\n",
    "Für die Äußerungen\n",
    "\n",
    ">  - `\"Wie warm war es 1990 in Berlin?\"`\n",
    ">  - `\"Welche Temperatur hatten wir in Hessen im Jahr 2018?\"`\n",
    ">  - `\"Wie komme ich zum Hauptbahnhof?\"`\n",
    "\n",
    "könnte _Intent Recognition_ also zum Beispiel jeweils folgende Ergebnisse liefern:\n",
    "\n",
    "> - `{'intent': 'Frag_Temperatur', 'slots': {'Ort': 'Berlin', 'Jahr': '1990'}}`\n",
    "> - `{'intent': 'Frag_Temperatur', 'slots': {'Ort': 'Hessen', 'Jahr': '2018'}}`\n",
    "> - `{'intent': 'Frag_Weg', 'slots': {'Start': None, 'Ziel': 'Hauptbahnhof'}}`\n",
    "\n",
    "Für Python steht eine ganze von NLP-Bibliotheken zur Verfügung, die Intent Recognition in der einen oder anderen Form ermöglichen, zum Beispiel\n",
    "\n",
    "- [Rasa NLU](https://rasa.com/docs/nlu/) (&bdquo;Language Understanding for chatbots and AI assistants&ldquo;),\n",
    "- [snips](https://snips-nlu.readthedocs.io/en/latest/) (&bdquo;Using Voice to Make Technology Disappear&ldquo;),\n",
    "- [DeepPavlov](http://deeppavlov.ai) (&bdquo;an open-source conversational AI library&ldquo;),\n",
    "- [NLP Architect](http://nlp_architect.nervanasys.com/index.html) von Intel (&bdquo;for exploring state-of-the-art deep learning topologies and techniques for natural language processing and natural language unterstanding&ldquo;),\n",
    "- [pytext](https://pytext-pytext.readthedocs-hosted.com/en/latest/index.html) von Facebook (&bdquo;a deep-learning based NLP modeling framework built on PyTorch&ldquo;).\n",
    "\n",
    "Wir entscheiden uns im Folgenden für die Bibliothek Rasa NLU, weil wir dafür bequem mit einem Open-Source-Tool (chatette) umfangreiche Trainingsdaten generieren können. Rasa NLU wiederum benutzt  die NLP-Bibliothek [spaCy](https://spacy.io), die Machine-Learning-Bibliothek [scikit-learn](https://scikit-learn.org/stable/) und die Deep-Learning-Bibliothek [TensorFlow](https://www.tensorflow.org/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Intent Recognition von Anfang bis Ende mit Rasa NLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Schauen wir uns an, wie man eine Sprach-Engine für Intent Recognition trainieren kann! Dafür beschränken wir uns zunächst auf wenige Intents und Trainingsdaten und gehen die benötigten Schritte von Anfang bis Ende durch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Schritt 1: Intents durch Trainingsdaten beschreiben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Als Erstes müssen wir die Intents mit Hilfe von Trainingsdaten beschreiben. _Rasa NLU_ erwartet beides zusammen in einer Datei im menschenfreundlichen [Markdown-Format](http://markdown.de/) oder im computerfreundlichen [JSON-Format](https://de.wikipedia.org/wiki/JavaScript_Object_Notation). Ein Beispiel für solche Trainingsdaten im Markdown-Format ist der folgende Python-String, den wir in die Datei `intents.md` speichern: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_INTENTS = \"\"\"\n",
    "## intent: Frag_Temperatur\n",
    "- Wie [warm](Eigenschaft) war es [1900](Zeit) in [Brandenburg](Ort)\n",
    "- Wie [kalt](Eigenschaft) war es in [Hessen](Ort) [1900](Zeit)\n",
    "- Was war die Temperatur [1977](Zeit) in [Sachsen](Ort)\n",
    "\n",
    "## intent: Frag_Ort\n",
    "- Wo war es [1998](Zeit) am [kältesten](Superlativ:kalt)\n",
    "- Finde das [kältesten](Superlativ:kalt) Bundesland im Jahr [2004](Zeit)\n",
    "- Wo war es [2010](Zeit) [kälter](Komparativ:kalt) als [1994](Zeit) in [Rheinland-Pfalz](Ort)\n",
    "\n",
    "## intent: Frag_Zeit\n",
    "- Wann war es in [Bayern](Ort) am [kühlsten](Superlativ:kalt)\n",
    "- Finde das [kälteste](Superlativ:kalt) Jahr im [Saarland](Ort)\n",
    "- Wann war es in [Schleswig-Holstein](Ort) [wärmer](Komparativ:warm) als in [Baden-Württemberg](Ort)\n",
    "\n",
    "## intent: Ende\n",
    "- Ende\n",
    "- Auf Wiedersehen\n",
    "- Tschuess\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "INTENTS_PATH = os.path.join(DATA_DIR, 'intents.md')\n",
    "\n",
    "\n",
    "def write_file(filename, text):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "\n",
    "write_file(INTENTS_PATH, TRAIN_INTENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Hier wird jeder Intent erst in der Form\n",
    "\n",
    "> `## intent: NAME`\n",
    "\n",
    "deklariert, wobei `NAME` durch die Bezeichnung des Intents zu ersetzen ist. Anschließend wird der Intent durch eine Liste von\n",
    "Beispiel-Äußerungen beschrieben. Die Parameter beziehungsweise Slots werden in den Beispieläußerungen in der Form\n",
    "\n",
    "> `[WERT](SLOT)`\n",
    "\n",
    "markiert, wobei `SLOT` die Bezeichnung des Slots und `Wert` der entsprechende Teil der Äußerung ist.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Schritt 2: Sprach-Engine konfigurieren..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Die Sprach-Engine von _Rasa NLU_ ist als Pipeline gestaltet und [sehr flexibel konfigurierbar](https://rasa.com/docs/nlu/components/#section-pipeline). Zwei [Beispiel-Konfigurationen](https://rasa.com/docs/nlu/choosing_pipeline/) sind in Rasa bereits enthalten:\n",
    "\n",
    "- `spacy_sklearn` verwendet vortrainierte Wortvektoren, eine [scikit-learn-Implementierung](https://scikit-learn.org/stable/modules/svm.html) einer linearen [Support-vector Machine]( https://en.wikipedia.org/wiki/Support-vector_machine) für die Klassifikation und wird für kleine Trainingsmengen (<1000) empfohlen. Da diese Pipeline vortrainierte Wortvektoren und spaCy benötigt, kann sie nur für [die meisten westeuropäische Sprachen](https://rasa.com/docs/nlu/languages/#section-languages) verwendet werden.\n",
    "\n",
    "- `tensorflow_embedding` trainiert für die Klassifikation Einbettungen von Äußerungen und von Intents in denselben Vektorraum  und wird für größere Trainingsmengen (>1000) empfohlen. Die zu Grunde liegende Idee stammt aus dem Artikel [StarSpace: Embed All The Things!](https://arxiv.org/abs/1709.03856). Sie ist sehr vielseitig anwendbar und beispielsweise auch für  [Question Answering](https://en.wikipedia.org/wiki/Question_answering) geeignet. Diese Pipeline benötigt kein Vorwissen über die verwendete Sprache, ist also universell einsetzbar, und kann auch auf das Erkennen mehrerer Intents in einer Äußerung trainiert werden.\n",
    "\n",
    "Zum Füllen der Slots verwenden beide Pipelines eine [Python-Implementierung](http://www.chokkan.org/software/crfsuite/) von [Conditional Random Fields](https://en.wikipedia.org/wiki/Conditional_random_field).\n",
    "\n",
    "Die Konfiguration der Pipeline wird durch eine YAML-Datei beschrieben. Der folgende Python-String entspricht der Variante `spacy_sklearn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "CONFIG_SK = \"\"\"\n",
    "language: de_core_news_sm\n",
    "pipeline:\n",
    "- name: \"nlp_spacy\"\n",
    "  case_sensitive: true\n",
    "- name: \"tokenizer_spacy\"\n",
    "- name: \"intent_entity_featurizer_regex\"\n",
    "- name: \"intent_featurizer_spacy\"\n",
    "- name: \"ner_crf\"\n",
    "- name: \"ner_synonyms\"\n",
    "- name: \"intent_classifier_sklearn\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Schritt 3: ...trainieren..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Sind die Trainingsdaten und die Konfiguration der Pipeline beisammen, so kann die Sprach-Engine trainiert werden. In der Regel erfolgt dies bei Rasa mit Hilfe eines Kommandozeilen-Interface oder direkt [in Python](https://rasa.com/docs/nlu/python/). Die folgende Funktion `train` erwartet die Konfiguration als Python-String und den Namen der Datei mit den Trainingsdaten und gibt die trainierte Sprach-Engine als Instanz einer `Interpreter`-Klasse zurück:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import rasa_nlu.training_data\n",
    "import rasa_nlu.config\n",
    "from rasa_nlu.model import Trainer, Interpreter\n",
    "\n",
    "MODEL_DIR = 'models'\n",
    "\n",
    "def train(config=CONFIG_SK, intents_path=INTENTS_PATH):\n",
    "    config_path = os.path.join(DATA_DIR, 'rasa_config.yml')\n",
    "    write_file(config_path, config)\n",
    "    trainer = Trainer(rasa_nlu.config.load(config_path))\n",
    "    trainer.train(rasa_nlu.training_data.load_data(intents_path))\n",
    "    return Interpreter.load(trainer.persist(MODEL_DIR))\n",
    "\n",
    "interpreter = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Schritt 4: ...und testen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Wir testen nun, ob die Sprach-Engine `interpreter` folgende Test-Äußerungen richtig versteht:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "TEST_UTTERANCES = [\n",
    "    'Was war die durchschnittliche Temperatur 2004 in Mecklenburg-Vorpommern',\n",
    "    'Nenn mir das wärmste Bundesland 2018',\n",
    "    'In welchem Jahr war es in Nordrhein-Westfalen heißer als 1990',\n",
    "    'Wo war es 2000 am kältesten',\n",
    "    'Bis bald',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Die Methode `parse` von `interpreter` erwartet eine Äußerung als Python-String, wendet Intent Recognition an und liefert eine sehr detaillierte Rückgabe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "interpreter.parse(TEST_UTTERANCES[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Die Rückgabe umfasst im Wesentlichen\n",
    "\n",
    "- den Namen des ermittelten Intent sowie eine Sicherheit beziehungsweise Konfidenz zwischen 0 und 1,\n",
    "- für jeden ermittelten Parameter die Start- und Endposition in der Äußerung, den Wert und wieder eine Konfidenz,\n",
    "- ein Ranking der möglichen Intents nach der Sicherheit/Konfidenz, mit der sie in dieser Äußerung vermutet wurden.\n",
    "\n",
    "Für eine übersichtlichere Darstellung und leichte Weiterverarbeitung bereiten wir die Rückgabe mit Hilfe der Funktionen `extract_intent` und `extract_confidences` ein wenig auf. Anschließend gehen wir unsere Test-Äußerungen durch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def extract_intent(intent):\n",
    "    return (intent['intent']['name'] if intent['intent'] else None,\n",
    "            [(ent['entity'], ent['value']) for ent in intent['entities']])\n",
    "\n",
    "\n",
    "def extract_confidences(intent):\n",
    "    return (intent['intent']['confidence'] if intent['intent'] else None,\n",
    "           [ent['confidence'] for ent in intent['entities']])\n",
    "\n",
    "\n",
    "def test(interpreter, utterances=TEST_UTTERANCES):\n",
    "    for utterance in utterances:\n",
    "        intent = interpreter.parse(utterance)\n",
    "        print('<', utterance)\n",
    "        print('>', extract_intent(intent))\n",
    "        print(' ', extract_confidences(intent))\n",
    "        print()\n",
    "\n",
    "test(interpreter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Das Ergebnis ist noch nicht ganz überzeugend &mdash;  wir haben aber auch nur ganz wenig Trainingsdaten vorgegeben!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "##  Trainingsdaten generieren mit Chatette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Für ein erfolgreiches Training brauchen wir also viel mehr Trainingsdaten. Doch fängt man an, weitere Beispiele aufzuschreiben, so fallen einem schnell viele kleine Variationsmöglichkeiten ein, die sich recht frei kombinieren lassen. Zum Beispiel können wir für eine Frage nach der Temperatur in Berlin im Jahr 1990 mit jeder der Phrasen\n",
    "> - \"Wie warm war es...\"\n",
    "> - \"Wie kalt war es...\"\n",
    "> - \"Welche Temperatur hatten wir...\"\n",
    "\n",
    "beginnen und dann mit\n",
    "\n",
    "> - \"...in Berlin 1990\"\n",
    "> - \"...1990 in Berlin\"\n",
    "\n",
    "abschließen, vor \"1990\" noch \"im Jahr\" einfügen und so weiter. Statt alle denkbaren Kombinationen aufzuschreiben, ist es sinnvoller, die Möglichkeiten mit Hilfe von Regeln zu beschreiben und daraus Trainingsdaten generieren zu lassen. Genau das ermöglicht das Python-Tool [chatette](https://github.com/SimGus/Chatette), das wir im Folgenden verwenden. Dieses Tool liest Regeln, die einer speziellen Syntax folgen müssen, aus einer Datei aus und erzeugt dann daraus Trainingsdaten für Rasa NLU im JSON-Format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Regeln zur Erzeugung von Trainingsdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Wir legen im Folgenden erst einen Grundvorrat an Regeln für die Intents `Frag_Temperatur`, `Frag_Ort`, `Frag_Zeit` und `Ende` in einem Python-Dictionary an und erläutern danach genauer, wie die Regeln aufgebaut sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "RULES = {\n",
    "    '@[Ort]': (\n",
    "        'Brandenburg', 'Baden-Wuerttemberg', 'Bayern', 'Hessen',\n",
    "        'Rheinland-Pfalz', 'Schleswig-Holstein', 'Saarland', 'Sachsen',\n",
    "    ),\n",
    "    '@[Zeit]': set(map(str, np.random.randint(1891, 2018, size=5))),\n",
    "    '@[Komparativ]': ('wärmer', 'kälter',),\n",
    "    '@[Superlativ]': ('wärmsten', 'kältesten',),\n",
    "    '%[Frag_Temperatur]': ('Wie {warm|kalt} war es ~[zeit_ort]',\n",
    "                  'Welche Temperatur hatten wir ~[zeit_ort]',\n",
    "                  'Wie war die Temperatur ~[zeit_ort]',\n",
    "    ),\n",
    "    '%[Frag_Ort]': (\n",
    "        '~[wo_war] es @[Zeit] @[Komparativ] als {@[Zeit]|in @[Ort]}',\n",
    "        '~[wo_war] es @[Zeit] am @[Superlativ]',\n",
    "    ),\n",
    "    '%[Frag_Jahr]': (\n",
    "        '~[wann_war] es in @[Ort] @[Komparativ] als {@[Zeit]|in @[Ort]}',\n",
    "        '~[wann_war] es in @[Ort] am @[Superlativ]',\n",
    "    ),\n",
    "    '%[Ende]': ('Ende', 'Auf Wiedersehen', 'Tschuess',),\n",
    "    '~[finde]': ('Sag mir', 'Finde'),\n",
    "    '~[wie_war]': ('Wie war', '~[finde]',),\n",
    "    '~[was_war]': ('Was war', '~[finde]',),\n",
    "    '~[wo_war]': ('Wo war', 'In welchem {Bundesland|Land} war',),\n",
    "    '~[wann_war]': ('Wann war', 'In welchem Jahr war',),\n",
    "    '~[zeit_ort]': ('@[Zeit] in @[Ort]', '@[Ort] in @[Zeit]',),\n",
    "    '~[Bundesland]': ('Land', 'Bundesland',),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Jede Regel besteht aus einem Namen beziehungsweise Platzhalter und einer Menge von Phrasen. Je nachdem, ob der Name die Form\n",
    "> `%[NAME]`, `@[NAME]` oder `~[NAME]`\n",
    "\n",
    "hat, beschreibt die Regel einen\n",
    "\n",
    "> _Intent_, _Slot_ oder eine _Alternative_\n",
    "\n",
    "mit der Bezeichnung `NAME`.  Jede Phrase kann ihrerseits Platzhalter für Slots und Alternativen erhalten. Diese Platzhalter werden bei der Erzeugung von Trainingsdaten von chatette jeweils durch eine der Phrasen ersetzt, die in der Regel für den jeweiligen Slot beziehungsweise die Alternativen aufgelistet sind. Außerdem können Phrasen\n",
    "\n",
    "- Alternativen der Form `{_|_|_}`,\n",
    "- optionale Teile in der Form `[_?]`\n",
    "\n",
    "und einige weitere spezielle Konstrukte enthalten. Mehr Details finden sich in der [Syntax-Beschreibung](https://github.com/SimGus/Chatette/wiki/Syntax-specifications) von chatette.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Erzeugung der Trainingsdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Die in dem Python-Dictionary kompakt abgelegten Regeln müssen nun für chatette so formatiert werden, dass bei jeder Regel der Name einen neuen Absatz einleitet und anschließend die möglichen Phrasen schön eingerückt Zeile für Zeile aufgelistet werden. Dies leistet die folgende Funktion `format_rules`.  Zusätzlich fügt sie eine Vorgabe ein, wieviel Trainingsbeispiele pro Intent erzeugt werden sollen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def format_rules(rules, train_samples):\n",
    "    train_str =  \"('training':'{}')\".format(train_samples)\n",
    "    llines = [[name if (name[0] != '%') else name + train_str]\n",
    "              + ['    ' + val for val in rules[name]] + [''] for name in rules]\n",
    "    return '\\n'.join((l for lines in llines for l in lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Nun wenden wir chatette an, um die Trainingsdaten zu generieren. Dafür bietet chatette ein bequemes [Kommandozeilen-Interface](https://github.com/SimGus/Chatette/wiki/Command-line-interface), aber wir verwenden direkt die zu Grunde liegenden Python-Module.\n",
    "\n",
    "Die folgende Funktion `chatette` erwartet wie `format_rules` ein Python-Dictionary mit Regeln, schreibt diese passend formatiert in eine Datei, löscht etwaige zuvor generierte Trainingsdateien und erzeugt dann den Regeln entsprechend neue Trainingsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from chatette.adapters import RasaAdapter\n",
    "from chatette.parsing import Parser\n",
    "from chatette.generator import Generator\n",
    "import glob\n",
    "\n",
    "TRAIN_SAMPLES = 400\n",
    "CHATETTE_DIR = os.path.join(DATA_DIR, 'chatette')\n",
    "\n",
    "\n",
    "def chatette(rules=RULES, train_samples=TRAIN_SAMPLES):\n",
    "    rules_path = os.path.join(DATA_DIR, 'intents.chatette')\n",
    "    write_file(rules_path, format_rules(rules, train_samples))\n",
    "    with open(rules_path, 'r') as rule_file:\n",
    "        parser = Parser(rule_file)\n",
    "        parser.parse()\n",
    "    generator = Generator(parser)\n",
    "    for f in glob.glob(os.path.join(CHATETTE_DIR, '*')):\n",
    "        os.remove(f)\n",
    "    RasaAdapter().write(CHATETTE_DIR, list(generator.generate_train()),\n",
    "                        generator.get_entities_synonyms())\n",
    "    \n",
    "chatette(train_samples=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Und nun: neue Tests!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Bringen die umfangreicheren Trainingsdaten wirklich eine Verbesserung? Schauen wir's uns an! Um verschiedene Sprach-Engines zu vergleichen, nutzen wir die folgende Funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_test(config=CONFIG_SK, utterances=TEST_UTTERANCES):\n",
    "    interpreter = train(config, CHATETTE_DIR)\n",
    "    test(interpreter, utterances)\n",
    "    return interpreter\n",
    "\n",
    "interpreter = train_and_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Das war die Sprach-Engine mit der Konfiguration `spacy_sklearn`. Die erste und die letzte Test-Äußerung wurden hier falsch verstanden, obwohl sie recht eindeutig klingen. Vergleichen wir das mit dem TensorFlow-Klassifikator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "CONFIG_TF = \"\"\"\n",
    "language: de_core_news_sm\n",
    "pipeline:\n",
    "- name: \"nlp_spacy\"\n",
    "  case_sensitive: true\n",
    "- name: \"tokenizer_spacy\"\n",
    "- name: \"ner_crf\"\n",
    "- name: \"ner_synonyms\"\n",
    "- name: \"intent_featurizer_count_vectors\"\n",
    "- name: \"intent_classifier_tensorflow_embedding\"\n",
    "\"\"\"\n",
    "interpreter = train_and_test(config=CONFIG_TF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Hier wurde nur die letzte Äußerung nicht verstanden, aber das ist auch nicht weiter verwunderlich."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "##  Unser kleiner WetterBot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Experimentieren macht mehr Spaß, wenn es auch mal zischt und knallt. Oder zumindest irgendeine andere Reaktion erfolgt. Und deswegen bauen wir uns einen kleinen WetterBot, der auf die erkannten Intents reagieren kann. Zuerst schreiben wir dafür eine Eingabe-Verarbeitungs-Ausgabe-Schleife. Diese erwartet als Parameter erstens die Sprach-Engine `interpreter` und zweitens ein Python-Dictionary `handlers`, welches jeder Intent-Bezeichnung einen Handler zuordnet. Der Handler wird dann mit dem erkannten Intent aufgerufen und sollte zurückgeben, ob die Schleife fortgeführt werden soll oder nicht:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def dialog(interpreter, handlers):\n",
    "    quit = False\n",
    "    while not quit:\n",
    "        intent = extract_intent(interpreter.parse(input('>')))\n",
    "        print('<', intent)\n",
    "        intent_name = intent[0]\n",
    "        if intent_name in handlers:\n",
    "            quit = handlers[intent_name](intent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Wir implementieren gleich beispielhaft einen Handler für den Intent `Frag_Temperatur`und reagieren auf alle anderen Intents mit einer Standard-Antwort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def message(msg, quit=False):\n",
    "    print(msg)\n",
    "    return quit\n",
    "\n",
    "HANDLERS = { \n",
    "    'Ende': lambda intent: message('=> Oh, wie schade. Bis bald!', True),\n",
    "    'Frag_Zeit': lambda intent: message('=> Das ist eine gute Frage.'),\n",
    "    'Frag_Ort': lambda intent: message('=> Dafür wurde ich nicht programmiert.'),\n",
    "    'Frag_Temperatur': lambda intent: message('=> Das weiss ich nicht.')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Um die Fragen nach den Temperaturen zu beantworten, nutzen wir [Archiv-Daten](ftp://ftp-cdc.dwd.de/pub/CDC/regional_averages_DE/annual/air_temperature_mean/regional_averages_tm_year.txt) des [Deutschen Wetterdienstes](https://www.dwd.de), die wir schon etwas aufbereitet haben. Die Routine `show` gibt die nachgefragten Temperaturdaten je nach Anzahl der angegebenen Jahre und Bundesländer als Liniendiagramm, Balkendiagramm oder in Textform an. Der eigentliche Hander `frag_wert` prüft, ob die angegebenen Jahre und Orte auch zulässig sind und setzt, falls eine der beiden Angaben fehlt, einfach alle Jahre beziehungsweise Bundesländer ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import set_matplotlib_formats\n",
    "%matplotlib inline\n",
    "set_matplotlib_formats('svg')\n",
    "\n",
    "sns.set()\n",
    "\n",
    "DATA_PATH = os.path.join(DATA_DIR, 'temperaturen.txt')\n",
    "temperature = pd.read_csv(DATA_PATH, index_col=0, sep=';')\n",
    "\n",
    "def show(times, places):\n",
    "    if (len(places) == 0) and (len(times) == 0):\n",
    "        print('Keine zulässigen Orte oder Zeiten')\n",
    "    elif (len(places) == 1) and (len(times) == 1):\n",
    "        print(temperature.loc[times, places])\n",
    "    else:\n",
    "        if (len(places) > 1) and (len(times) == 1):            \n",
    "            temperature.loc[times[0], places].plot.barh()\n",
    "        if (len(places) == 1) and (len(times) > 1):\n",
    "            temperature.loc[times, places[0]].plot.line()\n",
    "        if (len(places) > 1) and (len(times) > 1):\n",
    "            temperature.loc[times, places].plot.line()\n",
    "            plt.legend(bbox_to_anchor=(1.05,1), loc=2, borderaxespad=0.)\n",
    "        plt.show()\n",
    "\n",
    "def frag_temperatur(intent):\n",
    "    def validate(options, ent_name, fn):\n",
    "        chosen = [fn(value) for (name, value) in intent[1] if name == ent_name]\n",
    "        return list(set(options) & set(chosen)) if chosen else options\n",
    "    places = validate(list(temperature.columns), 'Ort', lambda x:x)\n",
    "    times = validate(list(temperature.index), 'Zeit', int)\n",
    "    show(times, places)\n",
    "    return False\n",
    "\n",
    "HANDLERS['Frag_Temperatur'] = frag_temperatur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Nun kann der WetterBot getestet werden! Zum Beispiel mit\n",
    "\n",
    ">  \"Wie warm war es in Baden-Württemberg und Sachsen?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dialog(interpreter, HANDLERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Und jetzt kannt Du loslegen &mdash; der WetterBot kann noch nicht viel, ist aber nun recht einfach zu trainieren! Ein paar Ideen dazu gibt Dir das Notebook mit Aufgaben zu Intent Recognition.\n",
    "\n",
    "_Viel Spaß und bis bald zu einer neuen Lektion vom codecentric.AI bootcamp!_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "name": "nlp-intent.ipynb",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "96px",
    "width": "250px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": null,
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
