{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# NLP Intent Recognition &mdash; Aufgaben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In diesem Notebook wollen wir den im Tutorial programmierten WetterBot erweitern. Dazu benötigen wir zunächst einige Deklarationen, Funktionen und Routinen aus dem Tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasa_nlu.training_data\n",
    "import rasa_nlu.config\n",
    "from rasa_nlu.model import Trainer, Interpreter\n",
    "\n",
    "from chatette.adapters import RasaAdapter\n",
    "from chatette.parsing import Parser\n",
    "from chatette.generator import Generator\n",
    "import glob\n",
    "\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "MODEL_DIR = 'models'\n",
    "INTENTS_PATH = os.path.join(DATA_DIR, 'intents.md')\n",
    "CHATETTE_DIR = os.path.join(DATA_DIR, 'chatette')\n",
    "TRAIN_SAMPLES = 200\n",
    "\n",
    "\n",
    "CONFIG_TF = \"\"\"\n",
    "language: de_core_news_sm\n",
    "pipeline:\n",
    "- name: \"nlp_spacy\"\n",
    "  case_sensitive: true\n",
    "- name: \"tokenizer_spacy\"\n",
    "- name: \"ner_crf\"\n",
    "- name: \"ner_synonyms\"\n",
    "- name: \"intent_featurizer_count_vectors\"\n",
    "- name: \"intent_classifier_tensorflow_embedding\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def write_file(filename, text):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "\n",
    "        \n",
    "def train(config=CONFIG_TF, intents_path=INTENTS_PATH):\n",
    "    config_path = os.path.join(DATA_DIR, 'rasa_config.yml')\n",
    "    write_file(config_path, config)\n",
    "    trainer = Trainer(rasa_nlu.config.load(config_path))\n",
    "    trainer.train(rasa_nlu.training_data.load_data(intents_path))\n",
    "    return Interpreter.load(trainer.persist(MODEL_DIR))\n",
    "\n",
    "\n",
    "def extract_intent(intent):\n",
    "    return (intent['intent']['name'] if intent['intent'] else None,\n",
    "            [(ent['entity'], ent['value']) for ent in intent['entities']])\n",
    "\n",
    "\n",
    "def extract_confidences(intent):\n",
    "    return (intent['intent']['confidence'] if intent['intent'] else None,\n",
    "           [ent['confidence'] for ent in intent['entities']])\n",
    "\n",
    "\n",
    "def test(interpreter, utterances):\n",
    "    for utterance in utterances:\n",
    "        intent = interpreter.parse(utterance)\n",
    "        print('<', utterance)\n",
    "        print('>', extract_intent(intent))\n",
    "        print(' ', extract_confidences(intent))\n",
    "        print()\n",
    "\n",
    "\n",
    "def format_rules(rules, train_samples):\n",
    "    train_str =  \"('training':'{}')\".format(train_samples)\n",
    "    llines = [[name if (name[0] != '%') else name + train_str]\n",
    "              + ['    ' + val for val in rules[name]] + [''] for name in rules]\n",
    "    return '\\n'.join((l for lines in llines for l in lines))\n",
    "\n",
    "\n",
    "def chatette(rules, train_samples=TRAIN_SAMPLES):\n",
    "    rules_path = os.path.join(DATA_DIR, 'intents.chatette')\n",
    "    write_file(rules_path, format_rules(rules, train_samples))\n",
    "    with open(rules_path, 'r') as rule_file:\n",
    "        parser = Parser(rule_file)\n",
    "        parser.parse()\n",
    "    generator = Generator(parser)\n",
    "    for f in glob.glob(os.path.join(CHATETTE_DIR, '*')):\n",
    "        os.remove(f)\n",
    "    RasaAdapter().write(CHATETTE_DIR, list(generator.generate_train()),\n",
    "                        generator.get_entities_synonyms())\n",
    "\n",
    "def generate_train_test(utterances, rules, config=CONFIG_TF):\n",
    "    chatette(rules)\n",
    "    test(train(config, CHATETTE_DIR), utterances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Unser WetterBot versteht bisher einfache Fragen nach Temperaturen, Orten und Jahren. Wir wollen ihm nun beibringen, die Temperatur nicht nur zu einzeln angegebenen Jahren, sondern auch zu Zeitspannen zu verraten, also Angaben der Form\n",
    "\n",
    "> 'von 1900 bis 2000'\n",
    "\n",
    "oder\n",
    "\n",
    "> 'zwischen 19777 und 1998'\n",
    "\n",
    "zu verstehen. Schauen wir uns zum Einstieg nochmal die Regeln an, die wir im Tutorial verwendet hatten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "RULES = {\n",
    "    '@[Ort]': (\n",
    "        'Brandenburg', 'Baden-Wuerttemberg', 'Bayern', 'Hessen',\n",
    "        'Rheinland-Pfalz', 'Schleswig-Holstein', 'Saarland', 'Sachsen',\n",
    "    ),\n",
    "    '@[Zeit]': set(map(str, np.random.randint(1891, 2018, size=5))),\n",
    "    '@[Komparativ]': set(['wärmer', 'kälter',]),\n",
    "    '@[Superlativ]': set(['wärmsten', 'kältesten',]),\n",
    "    '%[Frag_Temperatur]': set(['Wie {warm/kalt} war es ~[Zeit_Ort]',\n",
    "                               'Welche Temperatur hatten wir ~[Zeit_Ort]',\n",
    "                               'Wie war die Temperatur ~[Zeit_Ort]',]\n",
    "    ),\n",
    "    '%[Frag_Ort]': set([\n",
    "        '~[wo_war] es @[Zeit] @[Komparativ] als {@[Zeit]/in @[Ort]}',\n",
    "        '~[wo_war] es @[Zeit] am @[Superlativ]',]\n",
    "    ),\n",
    "    '%[Frag_Jahr]': set([\n",
    "        '~[wann_war] es in @[Ort] @[Komparativ] als {@[Zeit]/in @[Ort]}',\n",
    "        '~[wann_war] es in @[Ort] am @[Superlativ]',]\n",
    "    ),\n",
    "    '%[Ende]': set(['Ende', 'Auf Wiedersehen', 'Tschuess',]),\n",
    "    '~[finde]': set(['Sag mir', 'Finde']),\n",
    "    '~[wie_war]': set(['Wie war', '~[finde]',]),\n",
    "    '~[was_war]': set(['Was war', '~[finde]',]),\n",
    "    '~[wo_war]': set(['Wo war', 'In welchem {Bundesland|Land} war',]),\n",
    "    '~[wann_war]': set(['Wann war', 'In welchem Jahr war',]),\n",
    "    '~[Zeit_Ort]': set(['@[Zeit] in @[Ort]', '@[Ort] in @[Zeit]',]),\n",
    "    '~[Bundesland]': set(['Land', 'Bundesland',]),\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Die folgenden Testfragen sollten dann zum Beispiel richtig verstanden werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "TEST_UTTERANCES = ['Wie warm war es in Thüringen von 1990 bis 1996',\n",
    "                   'Welche Temperatur hatten wir zwischen 1974 und 1980 im Saarland',\n",
    "                   'Wie kalt war es 2010 und 2018 in Niedersachsen',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Insbesondere sollte bei der dritten Frage erkannt werden, dass keine Zeitspanne, sondern zwei einzelne Jahre gemeint sind. Mit den obigen Regeln werden diese Testfragen wie folgt verstanden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "generate_train_test(TEST_UTTERANCES, RULES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Aufgabe 1: Zusätzliche Slots `Start` und `Ende` im Intent `Frag_Temperatur`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Ergänze `RULES` zu einem Python-Dictionary `RULES_A` durch\n",
    "\n",
    "- neue Slots `@[Start]` und `@[Ende]`, die wie `@[Zeit]` Jahreszahlen als Beispiele haben,\n",
    "- zusätzliche Beispiele für die Regel `~[Zeit_Ort]` mit Zeitspannen (und den neuen Slots)\n",
    "\n",
    "und teste mit Hilfe von `generate_train_test`, ob die Test-Fragen dann richtig verstanden werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Aufgabe 2: Ein neuer Intent `Frag_Temperatur_Spanne`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Ergänze alternativ nun die Regeln `RULES` um einen neuen Intent `Frag_Temperatur_Spanne` zu einem Dictionary `RULES_B`, ohne die Trainingsdaten für den Intent `Frag_Temperatur` zu beeinflussen. Teste wieder, ob die Test-Fragen so besser verstanden werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Aufgabe 3: Zusätzliche Trainingsdaten für die Nennung zweier einzelner Jahre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Bei der dritten Testfrage wurden vielleicht in (b) die beiden einzelnen Jahre als Start und Ende einer Zeitspanne falsch verstanden. Können wir Abhilfe schaffen, indem wir solche Fragen in unsere Trainingsdaten aufnehmen? Teste das sowohl mit dem Ansatz aus Teilaufgabe (a) als auch mit dem Ansatz aus Teilaufgabe (b)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "name": "nlp-intent-solutions.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
