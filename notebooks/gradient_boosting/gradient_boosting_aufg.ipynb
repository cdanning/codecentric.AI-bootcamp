{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# codecentric.AI Bootcamp - Gradient Boosting & XGBoost\n",
    "\n",
    "## Aufgaben\n",
    "\n",
    "Hier findet ihr eine Reihe von Übungsaufgaben zu Gradient Boosting & XGBoost.\n",
    "\n",
    "Folge den Aufgaben und ergänze die ___ in den Code-Abschnitten.\n",
    "\n",
    "Die folgenden Pakete werden geladen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datensätze aus Scikit-learn\n",
    "\n",
    "Für die nachfolgenden Übungsaufgaben wollen wir zwei Datensätze verwenden, einen für Klassifikationsmodelle und einen anderen für Regressionsmodelle.\n",
    "\n",
    "- `iris`\n",
    "- `boston`\n",
    "\n",
    "Für mehr Informationen zu den Datensätzen, gucke dir das Random Forest Kapitel an!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Irisdaten für Klassifikation\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Boston Hauspreise für Regression\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_iris, target_iris = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_boston, target_boston = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten mit Scikit-learn in Trainings- und Testsets aufteilen\n",
    "\n",
    "Nun wollen wir die beiden Datensätze, die wir geladen haben, in Trainings- und Testsets aufteilen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(features_iris, \n",
    "                                                                        target_iris,\n",
    "                                                                        test_size = 0.2,\n",
    "                                                                        random_state = 42,\n",
    "                                                                        stratify = target_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_boston, X_test_boston, y_train_boston, y_test_boston = train_test_split(features_boston, \n",
    "                                                                                target_boston,\n",
    "                                                                                test_size = 0.2,\n",
    "                                                                                random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1: Klassifikation mit Gradient Boosting in Scikit-learn\n",
    "\n",
    "Nun sind unsere `iris` Daten bereit für das Trainieren von Modellen.\n",
    "\n",
    "- Importiere den Gradient Boosting Klassifikationsalgorithmus.\n",
    "- Definiere den Gradient Boosting Algorithmus mit den folgenden Hyperparametern: 100 Bäume mit maximaler Tiefe von 3, maximaler Anzahl in Betracht zu ziehender Instanzen pro Split von 3 und Lernrate von 0.1.\n",
    "- Trainiere das so definierte Modell auf den `iris` Trainingsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ___ import ___\n",
    "\n",
    "gbm_class = ___(\n",
    "    ___=0.1,\n",
    "    loss = \"deviance\",\n",
    "    ___ = 100,\n",
    "    ___ = 3,\n",
    "    min_samples_leaf = 3,\n",
    "    ___ = 3,\n",
    "    random_state = 42\n",
    ")\n",
    "___(___, ___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importiere die Funktion zur Erstellung von Wahrheitsmatrizen / confusion matrices aus Scikit-learn.\n",
    "- Nutze das Gradient Boosting Klassifikationsmodell um Vorhersagen auf den Testdaten zu machen.\n",
    "- Vergleiche die vorhergesagten Klassen mit den tatsächlichen Klassen des Testsets, indem du die Wahrheitsmatrix / confusion matrix ausgeben lässt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ___ import ___\n",
    "\n",
    "y_pred_gbm_class = ___(___)\n",
    "___(___, ___, labels=np.unique(y_test_iris))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2: Regression mit Gradient Boosting in Scikit-learn\n",
    "\n",
    "Auch unsere `boston` Daten sind bereit für das Trainieren von Modellen.\n",
    "\n",
    "- Importiere den Gradient Boosting Regressionsalgorithmus.\n",
    "- Definiere den Gradient Boosting Algorithmus mit den folgenden Hyperparametern: Least Squares Loss, 100 Bäume mit maximaler Tiefe von 3, maximaler Anzahl in Betracht zu ziehender Instanzen pro Split von 3 und Lernrate von 0.1.\n",
    "- Trainiere das so definierte Modell auf den `boston` Trainingsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ___ import ___\n",
    "\n",
    "gbm_reg = ___(\n",
    "    learning_rate=0.1,\n",
    "    loss = ___,\n",
    "    ___ = 100,\n",
    "    ___ = 3,\n",
    "    min_samples_leaf = 3,\n",
    "    ___ = 3,\n",
    "    random_state = 42\n",
    ")\n",
    "___(___, ___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nutze das Gradient Boosting Regressionsmodell um Vorhersagen auf den Testdaten zu machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gbm_reg = ___(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importiere die Funktion für den mittleren absoluten Fehler aus Scikit-learn.\n",
    "- Berechne den mittleren absoluten Fehler für die Vorhersagen der Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ___ import ___\n",
    "\n",
    "___(___, ___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datenvorbereitung für H2O\n",
    "\n",
    "Mit Scikit-learn hast du erfolgreich Klassifikations- und Regressionsmodelle mit Random Forest trainiert. Jetzt wollen wir uns angucken, wie das Ganze mit h2o funktioniert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "h2o.init(nthreads = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iris = load_iris()\n",
    "df_iris = pd.DataFrame(data_iris.data, columns=data_iris.feature_names)\n",
    "target_iris = pd.DataFrame({'class':data_iris.target})\n",
    "\n",
    "df_c_iris = pd.concat([target_iris, df_iris], axis=1)\n",
    "df_c_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_boston = load_boston()\n",
    "df_boston = pd.DataFrame(data_boston.data, columns=data_boston.feature_names)\n",
    "target_boston = pd.DataFrame({'target':data_boston.target})\n",
    "\n",
    "df_c_boston = pd.concat([target_boston, df_boston], axis=1)\n",
    "df_c_boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_iris = h2o.H2OFrame(df_c_iris)\n",
    "hf_iris[0] = hf_iris[0].asfactor()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iris, valid_iris, test_iris = hf_iris.split_frame([0.7, 0.15], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_X_iris = hf_iris.col_names[1:len(hf_iris.col_names)]\n",
    "hf_X_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_y_iris = hf_iris.col_names[0]\n",
    "hf_y_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 3: Gradient Boosting mit H2O\n",
    "\n",
    "- Importiere den H2O Gradient Boosting Estimator.\n",
    "- Definiere die Gradient Boosting Funktion aus `h2o` mit den folgenden [Hyperparametern](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html#h2ogradientboostingestimator): 300 Bäumen, maximaler Baumtiefe von 3 und Lernrate von 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ___ import ___\n",
    "\n",
    "gbm_h2o_class = ___(\n",
    "    ___ = 300,\n",
    "    ___ = 0.1,\n",
    "    ___ = 3,\n",
    "    min_rows = 3,\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trainiere den Random Forest Algorithmus mit den `iris` Trainings- und Validierungsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "___(x = ___, \n",
    "                    y = ___, \n",
    "                    ___ = train_iris, \n",
    "                    ___ = valid_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Berechne die Modell-Performance auf den Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_class = ___(test_data=___)\n",
    "print(performance_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regression mit H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_boston = h2o.H2OFrame(df_c_boston)\n",
    "train_boston, test_boston = hf_boston.split_frame([0.7], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_X_boston = hf_boston.col_names[1:len(hf_boston.col_names)]\n",
    "hf_X_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_y_boston = hf_boston.col_names[0]\n",
    "hf_y_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 4:\n",
    "\n",
    "- Definiere die Gradient Boosting Funktion aus `h2o` mit den folgenden [Hyperparametern](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html#h2ogradientboostingestimator): 300 Bäumen, maximaler Baumtiefe von 3 und Lernrate von 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_h2o_reg = ___(\n",
    "    ___ = 300,\n",
    "    ___ = 0.1,\n",
    "    ___ = 3,\n",
    "    min_rows = 3,\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trainiere den Gradient Boosting Algorithmus mit den `boston` Trainingsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "___(x = ___, \n",
    "             y = ___, \n",
    "             ___ = train_boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Berechne die Modell-Performance auf den Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_reg = ___(test_data=___)\n",
    "print(performance_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lasse dir Werte für die Antwortvariable für alle Testdaten vorhersagen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_boston = ___(___)\n",
    "pred_test_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese vorhergesagten Werte können wir zum Beispiel gegen die tatsächlichen Werte plotten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test_boston.as_data_frame().target, pred_test_boston.as_data_frame().predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Abbildung oben sehen wir auf der x-Achse die tatsächlichen Hauspreise, auf der y-Achse sehen wir die vorhersagten Preise. So können wir vergleichen, wie nahe unsere Vorhersage an der Wirklichkeit dran sind. Im perfekten Szenario, währen alle Werte gleich und die Punkte würden auf einer Geraden x=y liegen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 5: XGBoost mit Scikit-learn\n",
    "\n",
    "- Importiere das xgboost-Paket.\n",
    "- Definiere den XGBoost Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ___ as xgb\n",
    "xgboost = ___()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trainiere den XGBoost Classifier auf den Boston Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "___(___, ___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Und nutze das Modell für Vorhersagen auf den Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred_test_boston = ___(___)\n",
    "xgb_pred_test_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 6: XGBoost mit dem xgboost-Paket\n",
    "\n",
    "- Wandle die Trainings- und Testdaten des Boston-Datensatzes in DMatrizen um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix = ___(data=___,label=___)\n",
    "test_dmatrix = ___(data=___,label=___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiere die folgenden [Hyperparameter](https://xgboost.readthedocs.io/en/latest/parameter.html#general-parameters):\n",
    "\n",
    "- Maximale Baumtiefe von 3\n",
    "- Lernrate von 0.1\n",
    "- 80% Samplingrate für Instanzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {___:3, \n",
    "          ___:0.1, \n",
    "          ___:0.8,\n",
    "          'silent':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definiere eine Watchliste mit Trainings- und Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchlist = [___, ___]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trainiere das Modell mit 50 Boostingrunden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = ___(___=data_dmatrix, \n",
    "                ___=params, \n",
    "                ___=50,\n",
    "                ___=watchlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluiere das Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "___(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mache Vorhersagen auf den Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xgb = ___(___)\n",
    "preds_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implementiere XGBoost mit 3x Kreuzvalidierung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_cv = ___(dtrain=data_dmatrix, \n",
    "                params=params, \n",
    "                ___=3,\n",
    "                num_boost_round=50,\n",
    "                early_stopping_rounds=10,\n",
    "                metrics=\"rmse\", \n",
    "                as_pandas=True, \n",
    "                seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 7: XGBoost mit H2O\n",
    "\n",
    "- Lade die XGBoost Funktion aus H2O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ___ import ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiere das XGBoost-Modell mit den folgenden [Hyperparametern](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/xgboost.html):\n",
    "\n",
    "- Maximaler Baumtiefe von 2\n",
    "- 5x Kreuzvalidierung\n",
    "- 100 Bäume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_h2o = ___(\n",
    "    ___ = 2,\n",
    "    ___ = 5,\n",
    "    ___ = 100,\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trainiere das Modell auf den Boston-Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "___(x = ___, \n",
    "         y = ___, \n",
    "         training_frame = ___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Berechne die Performance auf den Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_xgb = ___(test_data=___)\n",
    "print(performance_xgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
