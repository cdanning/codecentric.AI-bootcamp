{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# codecentric.AI Bootcamp\n",
    "## Praxis: Machine Learning Basics\n",
    "\n",
    "Willkommen bei der Lektion zu den Grundlagen zu Machine Learning!\n",
    "\n",
    "Um das Erklärvideo zu diesem Notebook zu laden, führe folgende Zelle aus:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lade Video\n",
    "from IPython.display import IFrame    \n",
    "IFrame('https://www.youtube.com/embed/iXZ95iGRMzM', width=850, height=650)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir beginnen sehr einfach, um auch diejenigen von euch abzuholen, die noch nicht viel Erfahrung mit Python besitzen. \n",
    "Wenn Dir das Kapitel zu einfach erscheint - keine Sorge, im folgenden Kurs wird der Code noch anspruchsvoller ;-).\n",
    "\n",
    "## Import\n",
    "Zunächst importieren wir die benötigten Bibliotheken.\n",
    "\n",
    "- numpy - für eine effiziente Verarbeitung von multidimensionalen Arrays\n",
    "- matplotlib  - für die Visualisierung unserer Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion, damit die matplotlib Visualisierungen im Jupyter Notebook angezeigt werden (und nicht in einem separaten Fenster)\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pylab\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fangen wir mal ganz einfach an\n",
    "\n",
    "Wir definieren eine **einfache** Funktion und generieren damit ein paar Datenpunkte. Wir verwenden absichtlich ein stark vereinfachtes Beispiel, um die grundlegenden Prinzipien hinter Machine Learning und Deep-Learning einfach zu verdeutlichen. In der Realität sind die Modelle, Features und Algorithmen natürlich komplexer - aber ganz abstrakt betrachtet kann man auch das komplexeste Deep Learning auf die Annäherung einer mathematischen Funktion zurückführen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem einfachen Beispiel soll die folgende Funktion das Modell sein, welches wir lernen wollen:\n",
    "\n",
    "$$f(x)=1.5x^2 + 5 $$\n",
    "\n",
    "Es handelt sich um eine Funktion mit quadratischen Eigenschaften. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zunächst definieren wir eine Funktion, die wir annähern wollen\n",
    "f = lambda x: 1.5*x**2 + 5\n",
    "num_datenpunkte = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die lambda Schreibweise ist eine \"anonyme\" Funktion und hilft uns, Funktionen mit wenig Code auszudrücken. Die selbe Funktion kann ebenfalls mit dem folgenden Code definiert werden: `def f(x): return 1.5 * x**2 + 5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daten = np.array( [(x, f(x)) for x in range(num_datenpunkte)] )\n",
    "\n",
    "# jetzt geben wir die ersten beiden Tupel aus. Die Notation [:3] könnte man auch als [0:3] schreiben und bedeutet hier: \n",
    "# Elemente von 0 bis nicht einschließlich 3\n",
    "print(daten[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Notation mit `[x for x in something]` steht für eine sogenannte Python List Comprehension. Diese werden wir häufig verwenden und sehen. \n",
    "So können wir in einer kompakten Schreibweise Listen, Arrays und Dictionaries erzeugen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden visualisieren wir die Daten mit Matplotlib. Dabei stellen wir die Parameter für die Achsendarstellung (xlim und ylim) so ein, dass der Ursrpung des Koordinatensystems zu sehen ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(daten[:, 0], daten[:, 1])\n",
    "plt.ylim(bottom=0)\n",
    "plt.xlim(left=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nun generieren wir ähnliche Daten mit einer leichten Abweichung\n",
    "# die Funktion random.randint(-2,2) liefert Zufallszahlen zwischen -2 und 2\n",
    "noisy_daten = np.array( [(x, f(x) + random.randint(-2,2)*x) for x in range(num_datenpunkte)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# und nun zeigen wir beide Funktionen in einem Diagramm an\n",
    "plt.plot(daten[:, 1])\n",
    "plt.plot(noisy_daten[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kostenfunktionen: Abweichungen zwischen Vorhersage und Realität messen\n",
    "\n",
    "Jetzt übertragen wir dieses einfache Beispiel auf ein Problem, welches wir mit Machine Learning lösen wollen.\n",
    "Die \"noisy_daten\" sind dabei die Daten, die wir beobachtet haben (also unsere Labels). Im Alltag gibt es keine exakten Modelle - sondern Daten haben immer gewisse Abweichungen. Diese Daten könnten also zum Beispiel unsere Verkaufszahlen oder Daten eines Sensors sein.\n",
    "\n",
    "Die Funktion f(x) ist dabei das Modell, das wir lernen wollen. Also das Prinzip hinter diesen Daten. (Normalerweise kennen wir dieses zugrunde liegende Modell natürlich nicht, sondern müssen es \"lernen\")\n",
    "\n",
    "Ein einfacher Ansatz wäre nun, dass man einfach ein paar Modelle ausprobiert und versucht zu messen, wie gut dieses Modell zu unseren Labels passt. Um dies messen zu können, verwenden wir Kostenfunktionen. Bei Machine Learning Verfahren macht man genau das gleiche - man probiert verschiedene Modelle und sogenannte Hyperparameter aus und misst deren Ergebnisse. Natürlich gibt es hier inzwischen sehr clevere Verfahren, wie man möglichst schnell und zielführend zu einem \"optimalen\" Modell kommt - aber dazu kommen wir später. Für den Beginn reicht es zu verstehen, dass wir  verschiedene Einstellungen \"ausprobieren\" und vergleichen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# einfache Fehlerfunktion\n",
    "fehler = lambda x, y: abs(x - y)\n",
    "\n",
    "gesamt_fehler = 0\n",
    "\n",
    "# für jeden Datenpunkt wird die Abweichung zwischen Modell und noisy_daten berechnet\n",
    "for i in range(num_datenpunkte):\n",
    "    e = fehler(daten[i, 1], noisy_daten[i, 1])\n",
    "    print(\"Abweichung bei x={0} ist: {1}\".format(i, e))\n",
    "    gesamt_fehler += e\n",
    "    \n",
    "print(\"Fehler insgesamt: {}\".format(gesamt_fehler))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Berechnung derselben Fehlerfunktion mit Hilfe von numpy\n",
    "\n",
    "In dem obigen Code-Beispiel kann man sehr gut nachvollziehen, wie der Fehler berechnet wird. Für die Verarbeitung von großen Datenmengen sind Schleifen (in diesem Fall die for-Schleife) aber ungeeignet, da deren Ausführung eine hohe Berechnungszeit erfordert - sie sind schlichtweg zu langsam. \n",
    "\n",
    "Deshalb wird im Bereich Machine Learning sehr viel mit `numpy` gearbeitet. Mit numpy kann man hocheffizient Berechnungen auf sehr großen Arrays machen. Die gleiche Berechnung des Fehlers wie oben können wir mit numpy wie folgt durchführen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesamt_fehler_numpy = np.sum(abs( daten[:, 1] - noisy_daten[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gesamt_fehler_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur Verdeutlichung generieren wir nun einmal 10 Millionen Datenpunkte und vergleichen die Laufzeit bei der Fehlerberechnung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_datapoints = 10000000\n",
    "numpy_1_big = np.random.rand(many_datapoints)\n",
    "numpy_2_big = np.random.rand(many_datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gesamt_fehler_big = 0\n",
    "\n",
    "for i in range(many_datapoints):\n",
    "    e = fehler(numpy_1_big[i], numpy_2_big[i])\n",
    "    gesamt_fehler_big += e\n",
    "    \n",
    "print(\"MAE Big Arrays: \", gesamt_fehler_big/many_datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gesamt_fehler_numpy_big = np.sum(abs(numpy_1_big - numpy_2_big))\n",
    "\n",
    "print(\"MAE Big Arrays: \", gesamt_fehler_numpy_big/many_datapoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie zu sehen ist, ist die Berechnung mit numpy um ein Vielfaches schneller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die Fehlerfunktion als Metrik zur Evaluierung verschiedener Modelle\n",
    "\n",
    "Wir können nun mit der Hilfe der Fehlerberechung die Leistung verschiedener Modelle vergleichen. Dazu definieren wir jetzt einfach irgendein weiteres Modell und messen bzw. vergleichen die Fehler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineares_modell = lambda x: 2*x + 3\n",
    "\n",
    "andere_daten = np.array( [(x, lineares_modell(x)) for x in range(num_datenpunkte)] )\n",
    "\n",
    "gesamt_fehler_numpy_andere = np.sum(abs( andere_daten[:, 1] - noisy_daten[:, 1]))\n",
    "print(\"Fehler anderes Modell \", gesamt_fehler_numpy_andere)\n",
    "print(\"(zum Vergleich: {0})\".format(gesamt_fehler_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier noch eine Visualisierung mit dem linearen Modell\n",
    "plt.plot(andere_daten[:, 1])\n",
    "plt.plot(noisy_daten[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazit:\n",
    "\n",
    "- Durch die Ermittlung des \"gesamten Fehlers\" können wir die beiden Modelle einfach miteinander vergleichen.\n",
    "- Wir sehen, dass der Fehler beim ersten Modell geringer ist als beim zweiten.\n",
    "- In der Visualisierung können wir vermuten, dass unser lineares Modell hier \"zu einfach\" ist und nicht unsere Daten repräsentieren kann. Wobei man bei diesem Ausschnitt noch nicht genau sieht, dass die Daten nicht linear sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aber wir wollen ja beim Machine Learning nicht manuell verschiedene Modelle und Parameter ausprobieren.\n",
    "Bei diesem einfachen Beispiel ist das zwar noch möglich - in der Praxis sind Modelle aber viel komplexer und lassen sich nicht mehr intuitiv bestimmen. Dennoch sind die Prinzipien die selben - es geht darum, Parameter \"auszuprobieren\" und den Fehler zu messen. Mit Hilfe von Kostenfunktionen lassen sich effiziente Algorithmen implementieren, welche die Parameter eines Modells iterativ annähern. Wir haben in diesem Beispiel die Summe der absoluten Fehler zwischen dem Modell und den Labels verwendet. Diese wird natürlich immer größer, je mehr Datenpunkte wir \"testen\". Daher kann man diesen noch durch die Anzahl der Datenpunkte teilen und erhält so eine einfache Kostenfunktion: den durchschnittlichen absoluten Fehler, auf Englisch **\"Mean Absolute Error\"** (MAE) bezeichnet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_modell_1 = gesamt_fehler_numpy / num_datenpunkte\n",
    "MAE_modell_2 = gesamt_fehler_numpy_andere / num_datenpunkte\n",
    "print(MAE_modell_1, MAE_modell_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Formel für den MAE lautet:\n",
    "\n",
    "$$MAE(X, f)=\\frac1m \\sum_{i=1}^m|f(x_i) - y_i|$$\n",
    "\n",
    "- m ist dabei die Anzahl der Datenpunkte\n",
    "- X ist ein \"Array\" mit bekannten Features und Labels (in diesem vereinfachten Fall sind die Features einfach x=1, 2, 3... etc.)\n",
    "  - also zum Beispiel x1 = (3, 5, 8) <- Features\n",
    "  - und y1 = (3) <- Label\n",
    "- f ist unser Modell bzw. die Vorhersagefunktion\n",
    "- y sind die Labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalisieren vs. Over- / Underfitting\n",
    "\n",
    "Um besser zu verstehen, was Overfitting bedeutet, versuchen wir absichtlich ein \"overfitted\" Modell zu erstellen.\n",
    "Wir ermitteln eine Funktion, die möglichst durch alle unsere Trainingspunkte läuft. Dazu berechnen wir ein Polynom 7. Grades mit Hilfe von `numpy.polyfit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = noisy_daten[:, 0]\n",
    "y = noisy_daten[:, 1]\n",
    "\n",
    "p = np.polyfit(x, y, 7)\n",
    "f_poly = np.poly1d(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die resultierende Funktion mit Polynom 7. Grades ist hier dargestellt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dieser Funktion berechnen wir nun einige Datenpunkte und visualisieren diese anschließend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.linspace erzeugt hier 100 Datenpunkte zwischen dem ersten und dem letzten x Wert\n",
    "x_poly = np.linspace(x[0], x[-1], 100)\n",
    "# mit diesen x Werten berechnen wir den Verlauf der Funktion\n",
    "y_poly = f_poly(x_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# und jetzt visualisieren wir den Verlauf und markieren die eigentlichen Labels mit einem \"x\"\n",
    "plt.plot(x, y, 'x', x_poly, y_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen schon, dass die Funktion genau durch die x Punkte verläuft - d.h. es ist zu erwarten, dass unser Fehler sehr klein ist. Zur Kontrolle berechnen wir den Fehler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfitted_daten = np.array( [(x, f_poly(x)) for x in range(num_datenpunkte)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesamt_fehler_overfitted = np.sum(abs( overfitted_daten[:, 1] - noisy_daten[:, 1]))\n",
    "print(\"Mean Absolute Error {0:.12f}\".format(gesamt_fehler_overfitted/num_datenpunkte))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Fehler des overfitting Modells ist geringer (nahe 0) als der von unserem idealen Modell - **aber nur im Bereich von unseren Trainingsdaten (den Datenpunkten)**. Das Modell hat qausi die Datenpunkte auswendig gelernt und nicht das Konzept hinter den Daten verstanden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, 'x', x_poly, y_poly)\n",
    "plt.plot(daten[:, 1])\n",
    "plt.legend([\"Labels\", \"overfitted Modell\", \"generalisierendes Modell\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betrachten wir nun einen Datenpunkt, den das Modell nicht während des Trainings \"gesehen\" hat, sehen wir, wie schlecht das Modell trotz des geringen Fehlers ist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir erzeugen nochmal Daten, gehen aber über die Trainingsdaten hinaus (+1)\n",
    "x_poly = np.linspace(x[0], x[-1] + 1, 100)\n",
    "y_poly = f_poly(x_poly)\n",
    "plt.plot(x, y, 'x', x_poly, y_poly)\n",
    "plt.plot(daten[:, 1])\n",
    "plt.legend([\"Labels\", \"overfitted Modell\", \"generalisierendes Modell\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazit:\n",
    "\n",
    "Overfitting kann bedeuten, dass ein Fehler zwar sehr klein wird, sich aber ein Modell trotzdem nicht eignet, denn \n",
    "- es trifft nur auf den Trainingsdaten gute Vorhersagen\n",
    "- es generalisiert nicht, trifft also auf neuen Datenpunkten / Beobachtungen schlechte Vorhersagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Gegensatz dazu bedeutet \"Underfitting\", dass ein Modell eine zu einfache Funktion erlernt hat. Um Underfitting zu verdeutlichen, erstellen wir im folgenden Beispiel eine lineare Funktion, bei der wir wissen, dass diese niemals die quadratischen Eigenschaften unserer Daten abbilden kann:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsere Funktion soll ungefähr durch diese Punkte verlaufen:\n",
    "(x1, y1), (x2, y2) = noisy_daten[0], noisy_daten[-1]\n",
    "print(x1, y1, x2, y2)\n",
    "\n",
    "# daraus folgt das Modell: \n",
    "f_underfitting = lambda x: ( (y2-y1)/x2 ) * x + y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underfitted_daten = np.array( [(x, f_underfitting(x)) for x in range(num_datenpunkte)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, 'x', underfitted_daten[:, 1])\n",
    "plt.plot(daten[:, 1])\n",
    "plt.legend([\"Labels\", \"underfitted Modell\", \"generalisierendes Modell\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazit: \n",
    "\n",
    "Auch hier sehen wir, dass der Fehler im Bereich der Trainingsdaten nicht sehr groß sein wird. Man kann sich aber leicht vorstellen, dass die Abweichungen für größere Werte von x sehr groß werden. Das \"zu einfache\" Modell wird niemals in der Lage sein, unsere fiktiven Daten mit quadratischen Eigenschaften über einen großen Wertebereich gut vorherzusagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten splitten und Modelle messen\n",
    "\n",
    "Was kann man nun gegen Overfitting und Underfitting unternehmen? Und vor allem: wie merkt man, wie es um sein aktuelles Modell bestellt ist? Bei unserem einfachen Beispiel lässt sich das noch ganz gut visualisieren und intuitiv bewerten - in der Praxis sind dafür die Modelle aber meist zu komplex.\n",
    "\n",
    "Im Prinzip geht man in der Praxis wie folgt vor:\n",
    "\n",
    "- Teile die Daten auf in Trainings-, Validierungs- und Testdaten (engl. training set, validation set, test set)\n",
    "- Trainiere dein Modell nur auf den Trainingsdaten\n",
    "- Messe den Fehler auf den Trainingsdaten -> fehler(train)\n",
    "- nach einigen Durchläufen: Messe den Fehler auf dem Validierungsdatensatz (also auf Daten, die das Modell nicht \"kennt\"). In diesem Schritt wird nur der Fehler berechnet und es werden keine Parameter angepasst.\n",
    "\n",
    "Durch einen Vergleich der Werte fehler(train) und fehler(val) kann man bewerten, wie gut oder schlecht ein Modell generalisiert und anschließend Hyperparameter verändern, um zu überprüfen, ob bei anderen Konfigurationen bessere Ergebnisse zustande kommen. \n",
    "\n",
    "Der Testdatensatz kann genutzt werden, um nach der Optimierung eines Modells eine ungeschönte Qualitätsaussage über das Modell zu machen. Die Idee ist es, nur ein einziges mal Prognosen auf den Testdaten durchzuführen, um die Leistungsfähigkeit eines Modells zu messen. Eine weitere Optimierung nach diesem Durchlauf ist nicht sinnvoll, da man das Modell ggfs. zugunsten bestimmter Charakteristiken optimiert, die nur in den Testdaten existieren, aber nicht generell in den zu erwartenden Daten bestehen. Es wäre quasi ein Selbstbetrug und daher nicht aussagekräftig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jetzt brauchen wir etwas mehr Daten als vorher, damit wir was zum aufteilen haben\n",
    "# wir generieren zunächst 200 x-werte zwischen 0 und 10\n",
    "num_x = num_x = 200\n",
    "x_werte = np.linspace(0, 10, num_x)\n",
    "\n",
    "# nun erzeugen wir die Daten wieder mit einer leichten Abweichung zu unserem Modell\n",
    "mehr_daten = np.array( [(x, f(x) + random.randint(-2,2)*x) for x in x_werte] )\n",
    "\n",
    "plt.plot(mehr_daten[:,0], mehr_daten[:,1], \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir mischen die Daten durch, damit die Daten zufällig verteilt sind\n",
    "np.random.shuffle(mehr_daten)\n",
    "\n",
    "# wir definieren einen Split bei 90 % (also 90 % Training, 10 % Validation). Üblich sind Werte zwischen 80-90% je nach Daten.\n",
    "split = int(num_x * (0.9))\n",
    "\n",
    "# jetzt splitten wir die Daten auf - mit numpy slicing ganz einfach:\n",
    "train, val = mehr_daten[:split,:], mehr_daten[split:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzeige der Trainingsdaten kleinere blaue Punkte\n",
    "plt.plot(train[:, 0], train[:, 1], \".\")\n",
    "# Anzeige der Validierungsdaten als größere orangene Punkte\n",
    "plt.plot(val[:, 0], val[:, 1], \"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit einem Modell und einer Fehlerfunktion kann man nun den Fehler für die Trainingsdaten und für die Validierungsdaten berechnen und miteinander vergleichen. Hier kommt es vor allem auch auf den Trend der Werte in mehreren Trainingsrunden an.\n",
    "\n",
    "Am Anfang ist zu erwarten, dass sowohl fehler(train) als auch fehler(val) mehr oder weniger gleichmäßig kleiner werden. Dies bedeutet das Modell wird besser bzw. \"lernt\" etwas. Erreicht man dann einen Punkt, wo fehler(train) weiterhin kleiner wird aber fehler(val) gleich bleibt oder sogar größer wird beginnt das Modell zu overfitten. An dieser Stelle lernt das Modell nicht mehr das Konzept der Trainingsdaten, sondern die Traingsdaten selbst.\n",
    "\n",
    "Schauen wir uns einen fiktiven Trainingsverlauf an:\n",
    "\n",
    "| Trainingsrunde | fehler(train) | fehler(val)    |\n",
    "|----------------|---------------|----------------|\n",
    "|   1            | 17,4          | 20,3           |\n",
    "|   2            | 14,4          | 17,2           |\n",
    "|   3            | 8,4           | 10,5           |\n",
    "|   4            | 2,4           |  4,1           |\n",
    "|   5            | 1,4           |  6,1           | \n",
    "|   6            | 0,4           |  8,2           |\n",
    "\n",
    "Hier sehen wir, dass ab Runde 5 ein Overfitting beginnt. fehler(train) fällt weiter deutlich während fehler(val) wieder steigt. Das Modell kann also auf unbekannten Daten verhältnismäßig schlechter vorhersagen als auf bekannten Daten. Was wiederum bedeutet, dass es nicht mehr so gut generalisiert. Das ist in der Regel ein guter Zeitpunkt, um mit dem Training aufzuhören. Wenn man diesen Punkt nie erreicht, dann bedeutet das wahrscheinlich, dass ein Modell zu einfach ist.\n",
    "\n",
    "An dieser Stelle führt uns unser vereinfachtes Beispiel nicht mehr weiter (wir müssten zu viel selbst implementieren). Ab hier werden wir uns mit realen Datensätzen und mit Machine Learning Frameworks auseinander setzen. Die beschriebenen Konzepte werden uns häufig wieder begegnen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands On! mit einer Bildklassifikation \n",
    "\n",
    "Okay, das war jetzt viel Theorie ohne konkreten Praxisbezug ... das wollen wir nun ändern. Wir starten gleich richtig durch. In diesem Abschnitt laden wir einen Bilderdatensatz und klassifizieren diese. Was klassifizieren genau bedeutet, erkläre ich euch in einem anderen Kapitel. Wir verwenden als Frameworks `Keras`, `TensorFlow`. Als Machine Learning Verfahren verwenden wir neuronale Netze. Was das genau bedeutet sei an dieser Stelle unwichtig - wir werden aber die einfachen Prinzipien von vorher wiederfinden.\n",
    "\n",
    "An dieser Stelle ist es wichtig, zu verstehen, dass die Prinzipien von unserem stark vereinfachten Beispiel auch bei komplexen Deep Learning mit neuronalen Netzen ebenso gültig sind. Es funktioniert ganz ähnlich - nur die mathematischen Funktionen sind komplexer und es gibt viel mehr Parameter. Diese Komplexität wird für uns als Nutzer aber durch einfach anzuwendende Frameworks abstrahiert.\n",
    "\n",
    "Zuerst importieren wir Funktionen aus Keras, die wir im Folgenden benötigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zuerst müssen wir die Daten herunterladen\n",
    "# entferne dazu die Kommentare und führe die Befehle aus\n",
    "\n",
    "#!wget https://bootcamp.codecentric.ai/data/fruits-360.zip -O /data/fruits-360.zip\n",
    "!apt install unzip\n",
    "!cd /data/ && unzip fruits-360.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_list = [\"Kiwi\", \"Banana\", \"Plum\", \"Apricot\", \"Avocado\", \"Cocos\", \"Clementine\", \"Mandarine\", \"Orange\",\n",
    "                \"Limes\", \"Lemon\", \"Peach\", \"Plum\", \"Raspberry\", \"Strawberry\", \"Pineapple\", \"Pomegranate\"]\n",
    "output_n = len(fruit_list)\n",
    "size = 20\n",
    "img_width = 20\n",
    "img_height = 20\n",
    "channels = 3\n",
    "train_image_files_path = \"/data/fruits-360/Training/\"\n",
    "valid_image_files_path = \"/data/fruits-360/Test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beispiel_bilder = !find $train_image_files_path -type f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_beispiel_bilder = 24\n",
    "beispiel_bilder = random.sample(beispiel_bilder, num_beispiel_bilder)\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "for i in range(num_beispiel_bilder):\n",
    "    fig.add_subplot(4, 6, i + 1)\n",
    "    plt.axis('off')\n",
    "    img = plt.imread(beispiel_bilder[i])\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(\n",
    "    rescale = 1 / 255 #,\n",
    ")\n",
    "\n",
    "valid_data_gen = ImageDataGenerator(\n",
    "    rescale = 1 / 255\n",
    ")\n",
    "\n",
    "train_image_array_gen = train_data_gen.flow_from_directory(\n",
    "        train_image_files_path,\n",
    "        target_size = (img_width, img_height),\n",
    "        class_mode = 'categorical',\n",
    "        classes = fruit_list,\n",
    "        seed = 42)\n",
    "\n",
    "valid_image_array_gen = valid_data_gen.flow_from_directory(\n",
    "        valid_image_files_path,\n",
    "        target_size = (img_width, img_height),\n",
    "        class_mode = 'categorical',\n",
    "        classes = fruit_list,\n",
    "        seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = train_image_array_gen.n\n",
    "valid_samples = valid_image_array_gen.n\n",
    "print(train_samples, valid_samples)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wir definieren die Architektur des neuronalen Netzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "model.add(Conv2D(32, (3, 3), padding = \"same\", input_shape = (img_width, img_height, channels)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# second hidden layer\n",
    "model.add(Conv2D(16, (3, 3), padding = \"same\"))\n",
    "model.add(LeakyReLU(alpha = 0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# max pooling\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten max filtered output into feature vector \n",
    "# and feed into dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Outputs from dense layer are projected onto output layer\n",
    "model.add(Dense(output_n))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = RMSprop(lr = 0.0001, decay = 1e-6),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wir trainieren das Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_image_array_gen,\n",
    "    steps_per_epoch = int(train_samples / batch_size), \n",
    "    epochs = epochs, \n",
    "    validation_data = valid_image_array_gen,\n",
    "    validation_steps = int(valid_samples / batch_size),\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wir messen die Genauigkeit des Modells (engl. Accuracy)\n",
    "Die Definition von Genauigkeit lautet wie folgt:\n",
    "- Genauigkeit = Anzahl richtiger Prognosen / Anzahl aller Prognosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc = 'lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc = 'upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazit:\n",
    "\n",
    "Mit ein paar Zeilen Code haben wir:\n",
    "\n",
    "- ein Datensatz mit Labels geladen\n",
    "- eine mathematische Funktion mit vielen Parametern definiert (in unserem Fall ein neuronales Netz)\n",
    "- eine Kostenfunktion definiert (in dem Fall loss = categorical_crossentropy)\n",
    "- iterativ ein Modell trainiert (mit model.fit())\n",
    "- verschiedene Modelle miteinander verglichen (Auswertung von Training Accuracy und Validation Accuracy)\n",
    "\n",
    "### Resultat:\n",
    "\n",
    "Die Validation Accuracy liegt bei > 99,9%. Das bedeutet, dass mit diesem einfachen Code und ein paar Minuten Trainingszeit wir eine Bildklassifikation durchführen konnten. Von unseren knapp 3000 Bildern aus dem Validation Set werden über 99,9% davon korrekt in eine von 81 Klassen einsortiert.\n",
    "\n",
    "Dieses Beispiel ist einfach übertragbar auf alle möglichen Bereiche. Auf genau die gleiche Art und Weise könnte man:\n",
    "\n",
    "- fehlerfreie von fehlerhaften Bauteilen unterscheiden\n",
    "- medizinische Bilder auswerten\n",
    "- Objekte in Qualitätsstufen einsortieren\n",
    "- Fotos automatisch kategorisieren\n",
    "\n",
    "... man muss \"nur\" die Bilder und die Labels bereitstellen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nun wünsche ich Dir viel Erfolg bei den Übungsaufgaben :-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
