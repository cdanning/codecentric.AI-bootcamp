{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# codecentric.AI Bootcamp - Convolutional Neural Networks\n",
    "\n",
    "## Aufgaben + Lösungen\n",
    "\n",
    "Hier findet ihr die Lösungen zu den Convolutional Neural Networkst.\n",
    "\n",
    "Die folgenden Pakete werden geladen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image processing\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# build your own nets\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten\n",
    "\n",
    "Die Daten (also die Bilder), die wir verwenden, sind von [Kaggle](https://www.kaggle.com/moltean/fruits/data) und zeigen verschiedene Früchte auf weißem Hintergrund. Einen Teil dieser Früchte haben wir euch in den `data` Ordner gelegt, damit ihr direkt loslegen könnt. Diese Bilder sind in dem Ordner `fruits-360` gespeichert, der zwei Unterordner enthält: `Training` und `Test`. Beide Unterordner enthalten wieder Unterordner mit den Namen der einzelnen Früchte. Hier wollen wir die **Trainingsbilder** zu trainieren des CNNs verwenden und die Testbilder zum testen. Entsprechend definieren wir die Pfade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_files_path = \"/data/fruits-360/Training/\"\n",
    "test_image_files_path = \"/data/fruits-360/Test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1: Vorbereitung des Modells\n",
    "\n",
    "Definiere die folgenden Objekte:\n",
    "\n",
    "- `fruit_list`: Suche dir 10 verschiedene Früchte aus dem Trainingsordner aus und definiere sie in einer Liste\n",
    "- `output_n`: Anzahl der **Klassen** (also der zu klassifizierenden Früchte).\n",
    "- `img_width` und `img_height`: **Größe** der Bilder auf 25 x 25 runterskaliert.\n",
    "- `channels`: Anzahl der **Farbkanäle**. Hier 3, da wir Farbbilder mit RGB-Kanälen haben.\n",
    "- `batch_size`: Definiert die Anzahl der Bilder, die gemeinsam den Optimierungs- + Backpropagation-Prozess durchlaufen. Soll hier 16 sein.\n",
    "- `epochs`: Anzahl der Runden (**Epochen**), die unser CNN trainiert werden soll. Wir starten mit 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_list = ___\n",
    "\n",
    "output_n = ___\n",
    "img_width = ___\n",
    "img_height = ___\n",
    "channels = 3\n",
    "\n",
    "batch_size = ___\n",
    "epochs = ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2: Bilder mit Keras einlesen\n",
    "\n",
    "- Definiere die `ImageDataGenerator` für Trainingsdaten.\n",
    "- Skaliere die Bilder indem durch den maximalen Pixelwert von 255 geteilt wird.\n",
    "- Definiere einen Validierungssplit von 30% (**Hinweis:** Gucke dir die Hilfe der Funktion mit `?ImageDataGenerator` an)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ___(\n",
    "    rescale = ___,\n",
    "    ___\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lade die **Trainingsbilder** mit der `flow_from_directory` Funktion.\n",
    "- Lade die **Validierungsbilder** mit der `flow_from_directory` Funktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_array_gen = ___(\n",
    "    ___,\n",
    "    target_size = ___,\n",
    "    class_mode = ___,\n",
    "    classes = ___,\n",
    "    color_mode = ___, \n",
    "    batch_size = ___,\n",
    "    ___ = ___,\n",
    "    seed = 42)\n",
    "\n",
    "valid_image_array_gen = ___(\n",
    "    ___,\n",
    "    target_size = ___,\n",
    "    class_mode = ___,\n",
    "    classes = ___,\n",
    "    color_mode = ___, \n",
    "    batch_size = ___,\n",
    "    ___ = ___,\n",
    "    seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 3: Das Keras-Modell erstellen\n",
    "\n",
    "- Starte mit der Initialisierung des sequentiellen Modells.\n",
    "- Füge einen Convolution Layer hinzu mit 16 Filtern, Fenstergröße von 3x3 und Schrittgröße von 1.\n",
    "- Füge eine ReLU-Aktivierung hinzu.\n",
    "- Füge einen zweiten Convolution Layer hinzu mit xx Filtern, Fenstergröße von 3x3 und Schrittgröße von 1.\n",
    "- Füge eine weitere ReLU-Aktivierung hinzu.\n",
    "- Füge Batch-Normalisierung hinzu.\n",
    "- Füge eine Max-Pooling-Schicht mit 2x2 Fenstern hinzu.\n",
    "- Füge 25% Dropout hinzu.\n",
    "- \"Flatte\" die Daten und füge einen Dense Layer mit 300 Knoten hinzu.\n",
    "- Füge eine weitere ReLU-Aktivierung hinzu.\n",
    "- Füge nochmal 25% Dropout hinzu.\n",
    "- Füge die Output-Schicht hinzu.\n",
    "- Nutze in dieser Schicht die Softmax-Aktivierungsfunktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ___\n",
    "___(___ = 16, \n",
    "                 kernel_size = ___,\n",
    "                 strides = ___,\n",
    "                 padding = \"same\", \n",
    "                 input_shape = ___)\n",
    "___\n",
    "___(___, padding = \"same\"))\n",
    "___\n",
    "___\n",
    "___\n",
    "___\n",
    "___\n",
    "___\n",
    "___\n",
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kompiliere das Modell mit kategorischer Kreuzentropie und dem Adam-Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "___(loss = ___, \n",
    "              optimizer = ___(lr = 0.0001),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definiere die Anzahl der Trainings- und Validierungsproben in den folgenden Objekten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = ___\n",
    "valid_samples = ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 4: Das Modell trainieren\n",
    "\n",
    "- Trainiere das Modell mit Trainings- und Validierungsdaten für die oben definierte Anzahl an Epochen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ___(\n",
    "    ___,\n",
    "    steps_per_epoch = int(train_samples / batch_size), \n",
    "    epochs = epochs, \n",
    "    validation_data = ___,\n",
    "    validation_steps = int(valid_samples / batch_size),\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 5: Vorhersage auf Testdaten\n",
    "\n",
    "- Definiere wieder einen `ImageDataGenerator` und benutze `flow_from_directory`, dieses Mal aber für die Testdaten im Ordner \"Test\", wie wir ihn oben definiert haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_gen = ___(\n",
    "    ___\n",
    ")\n",
    "\n",
    "test_image_array_gen = ___(\n",
    "    ___,\n",
    "    target_size = (img_width, img_height),\n",
    "    class_mode = ___,\n",
    "    classes = ___,\n",
    "    color_mode = 'rgb', \n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definiere nun die Anzahl der Trainingsbilder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bewerte die Vorhersage auf Testbildern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "___(___,\n",
    "    steps = int(test_samples / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der oben zu sehenden Output zeigt die Performance-Metriken Loss und Genauigkeit (`model.metrics_names`). \n",
    "\n",
    "Alternativ können wir auch ohne Kenntnisse der Klassen Vorhersagen auf Testdaten machen. Dafür definieren wir `flow_from_directory` wie folgt mit class mode als \"None\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_array_gen = ___(\n",
    "    ___,\n",
    "    target_size = (img_width, img_height),\n",
    "    class_mode = ___,\n",
    "    color_mode = 'rgb', \n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wende die Vorhersagefunktion aus Keras auf dem `ImageDataGenerator` an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ___(___,\n",
    "           steps = int(test_samples / batch_size))\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "predicted_class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (train_image_array_gen.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.sample(predictions, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
