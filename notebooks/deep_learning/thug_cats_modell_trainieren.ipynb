{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ein eigenes \"Thug Cats\" Modell trainieren\n",
    "### codecentric.ai Bootcamp\n",
    "\n",
    "1. melde dich bei kaggle.com an\n",
    "2. suche nach \"cats dataset\"\n",
    "3. lade cats.zip Datei herunter (~ 2 GB)\n",
    "4. entpacke die zip Datei in einen Ordner (z.B. /data/cats/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn du keine geeignete GPU in deinem Rechner zum Trainieren hast, dann schau dir zunächst das Video an, wie man eine Cloud Instanz mit GPU einrichtet. Das Training auf einer \"normalen\" CPU mit dieser Datenmenge dauert sehr lange (zu lange). \n",
    "\n",
    "Wir gehen im folgenden davon aus, dass du dieses Notebook auf einer Cloud Instanz ausführst. \n",
    "\n",
    "Logge dich auf deiner Cloud Instanz ein:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Füge deinen AWS Key dem SSH Agent hinzu, damit du dich anmelden kannst ohne immer das Keyfile\n",
    "# angeben zu müssen\n",
    "\n",
    "ssh-add .ssh/AWS_KEY.pem\n",
    "\n",
    "# SSH Connection mit SSH Tunnel für Port 8890 (damit du den Port des Jupyter Servers erreichen kannst \n",
    "# ohne die AWS \"Firewall\" auf zu machen)\n",
    "\n",
    "ssh ubuntu@AWS_IP -L 8890:localhost:8890\n",
    "\n",
    "# aktiviere das (richtige) python virtual environment (pytorch mit python 3.6)\n",
    "\n",
    "source python_36/bin/activate\n",
    "\n",
    "# clone das Bootcamp Repo mit den Übungs-Notebooks\n",
    "\n",
    "git clone https://github.com/codecentric/codecentric.AI-bootcamp.git\n",
    "cd codecentric.AI-bootcamp\n",
    "\n",
    "# Starte den Jupyter Server\n",
    "\n",
    "jupyter notebook --port=8890\n",
    "\n",
    "```\n",
    "\n",
    "Dann öffne dieses Notebook auf der Cloud-Instanz indem du http://localhost:8890/ aufrufst.\n",
    "\n",
    "\n",
    "Um die Daten (cats.zip) auf die Cloud Instanz zu kopieren, kannst du zum Beispiel `scp` verwenden:\n",
    "\n",
    "```\n",
    "scp cats.zip ubuntu@AWS_IP:~/codecentric.AI-bootcamp/data\n",
    "```\n",
    "\n",
    "Nun installieren wir noch ein paar Libraries, die wir benötigen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastai==1.0.52 \\\n",
    " uvicorn \\\n",
    " aiofiles \\\n",
    " aiohttp \\\n",
    " jupyter \\\n",
    " imutils \\\n",
    " matplotlib \\\n",
    " numpy \\\n",
    " opencv-python \\\n",
    " Pillow \\\n",
    " pandas \\\n",
    " requests\\\n",
    " starlette\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das Training verwenden wir fastai:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten auspacken und ansehen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfad zu den Daten\n",
    "path = Path(\"/data/cats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Bilder und Labels liegen in Unterordnern CAT_00 - CAT_06:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem Unterornder sehen die Daten so aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(os.listdir(path/'CAT_00'))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilder und Labels visualisieren\n",
    "\n",
    "Wir schauen uns ein konkretes Beispiel an, bevor wir unser Modell trainieren, um zu verstehen, wie die Daten strukturiert sind. Dazu picken wir uns einfach einen Dateinamen raus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_str = \"CAT_00/00000001_005.jpg\"\n",
    "sample_img = open_image(path/sample_str)\n",
    "sample_labels_file = path/str(sample_str+\".cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die \".cat\" Datei ist ein einfaches Text-File mit Zahlenwerten. \n",
    "\n",
    "Anhand des Dateinamens wird sie dem entsprechenden Bild zugeordnet \n",
    "(xx1_005.jpg.cat sind die Labels für xx1_005.jpg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(sample_labels_file, \"r\")\n",
    "print(f.readline())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt lesen wir die \".cat\" Datei in ein numpy Array ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_points = np.genfromtxt(sample_labels_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit haben wir die Labels in einem Array.\n",
    "\n",
    "- die erste Zahl bedeutet die Anzahl der Datenpunkte (immer 9)\n",
    "- dann folgen jeweils Tupel, die einen Bild Punkt bedeuten\n",
    "- der erste Tupel ist (x, y) vom linken Auge\n",
    "- der zweite Tupel ist (x, y) vom rechten Auge\n",
    "- die Reihenfolge der Labels ist immer gleich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt bringen wir die Daten noch in ein passendes Format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# die erste Zahl ist immer 9 - die brauchen wir nicht\n",
    "sample_np = sample_points[1:]\n",
    "\n",
    "# jetzt vertauschen wir noch pro Tupel y->x, also aus p2=(153, 127) wird (127, 153)\n",
    "# dies macht es einfacher die vorhandenen Visualisierungsfunktionen zu verwenden\n",
    "# je nachdem welche library man verwendet kann es sein, dass man dort einen punkt mit (x,y) oder mit (y,x) definiert\n",
    "sample_np = np.array(sample_np.reshape(9,2)[:, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wandeln wir den Array in einen Tensor um:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor = torch.tensor(sample_np, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und schließlich bringen wir das ganze in das Daten-Format mit dem fastai arbeitet, um Bilder und Bildpunkte als Labels anzeigen zu können:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_field = FlowField(sample_img.size, sample_tensor)\n",
    "image_points = ImagePoints(flow_field, scale=True)\n",
    "sample_img.show(y=image_points, figsize=(7, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen, dass das Bild richtig angezeigt wird.\n",
    "\n",
    "Außerdem sehen wir, dass die Labels (rote Punkte) an den richtigen Stellen angezeigt werden. \n",
    "\n",
    "Damit sind wir sicher, dass wir die Struktur der Daten verstanden haben und sind bereit, unser Modell zu trainieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Databunch erstellen\n",
    "\n",
    "In fastai gibt es ein sogenanntes \"databunch\".\n",
    "\n",
    "Darin sind viele Schritte gekapselt:\n",
    "\n",
    "- Daten laden\n",
    "- Daten labeln\n",
    "- Daten transformieren / normalisieren\n",
    "- aufsplitten in TRAIN und VALIDATION sets\n",
    "- aufsplitten in Batches\n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/data/cats/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus dem Beispiel-Bild oben, wissen wir, wie wir die Labels strukturieren müssen, damit die Library damit arbeiten kann. Diese Schritte packen wir nun in eine Funktion, um sie auf alle Bilder anwenden zu können:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keypoints(file_name):\n",
    "    file_name = str(file_name)+\".cat\"\n",
    "    keypoints = np.genfromtxt(file_name)[1:]\n",
    "    keypoints = np.array(keypoints.reshape(9,2)[:, ::-1])\n",
    "    t = torch.tensor(keypoints, dtype=torch.float)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dieser Funktion können wir nun ein databunch erzeugen. Dieser liest alle Bilder unter `path`, splittet die Daten zufällig in Train- und Validation-Set, ermittelt die Labels mit der oben definierten Funktion, bringt die Bilder in eine einheitliche Größe und normalisiert die Bilddaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit dieser Bildgröße soll unser neuronales Netz trainieren\n",
    "size = (220, 300)\n",
    "# das ist die Batch-Size\n",
    "bs = 64\n",
    "\n",
    "data = (PointsItemList.from_folder(path)\n",
    "        #.filter_by_func(lambda o: str(o).endswith('.jpg'))\n",
    "        .split_by_rand_pct()\n",
    "        .label_from_func(get_keypoints)\n",
    "        #.transform(get_transforms(), tfm_y=True, size=size, remove_out=False)\n",
    "        .transform([], tfm_y=False, size=size)\n",
    "        .databunch(bs=bs, num_workers=0).normalize(imagenet_stats)\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt haben wir ein \"data\" Objekt und können es verwenden, um die Daten zu laden und anzuzeigen (so wie sie dann für das Training verwendet werden, inklusive Resizing etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Daten sehen gut aus, jetzt können wir unser Modell definieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modell (bzw. learner) definieren\n",
    "\n",
    "Dazu verwenden wir ein pretrained ResNet34. Wir machen uns keine großen Gedanken, um die Architektur des neuronalen Netzes - sondern probieren einfach einmal aus, wie weit wir mit einer modernen Standard-Architektur kommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, models.resnet34, pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folgende Funktion aus fastai macht ein kleines \"Probe-Training\" und hilft uns dabei abzuschätzen, wie groß die learning rate sein sollte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training starten\n",
    "\n",
    "Jetzt haben wir alle Vorbereitungen getroffen und können das Training des Modells starten.\n",
    "\n",
    "Wir trainieren erstmal 3 Epochen und schauen uns dann an, ob unser Netz etwas \"Sinnvolles\" lernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(3, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_loss und valid_loss werden kleiner -> schon mal gut.\n",
    "\n",
    "Mit der folgenden Methode können wir mit dem aktuellen Modell ein paar Predictions machen lassen und visualisieren, wie gut/schlecht es funktioniert. \n",
    "\n",
    "In der linken Spalte sieht man den \"Ground truth\" (also das Label) und in der Spalte rechts daneben die Vorhersage, die das Modell für dieses Bild gemacht hat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(rows=5, figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man sieht, dass die Punkte schon in der Nähe des Kopfes sind - aber sie markieren noch nicht wirklich Augen, Ohren etc. Wir versuchen also noch weiter zu trainieren, um das Modell zu verbessern. \n",
    "\n",
    "Dazu machen wir zunächst ein \"unfreeze\" - das heisst wir trainieren jetzt alle Layer und nicht nur die letzten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt verwenden wir eine optimierte fit Methode und lassen das Modell einfach mal eine Weile trainieren.\n",
    "\n",
    "Zeit für einen Kaffee (oder 2). \n",
    "\n",
    "Nur so nebenbei: das Modell trainiert nicht schneller oder besser, wenn man dem Progress-Bar zuschaut - aber viele machen es trotzdem ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 4e-4\n",
    "learn.fit_one_cycle(20, slice(lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der folgenden Funktion können wir den Verlauf train_loss und valid_loss visualisieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das Training nicht immer wieder von vorne beginnen zu müssen, kann man den aktuellen Stand in einer Datei speichern (und einfach und schnell wieder laden, falls man etwas \"kaputt\" macht oder das nächste Experiment in die falsche Richtung geht):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('thug_cat_resnet34_v1')\n",
    "learn.load('thug_cat_resnet34_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt schauen wir uns noch einmal an, ob sich das Modell verbessert hat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(rows=10, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man sieht, dass die Predictions nun schon ganz gut auf die entsprechenden Punkte passen.\n",
    "\n",
    "Man könnte versuchen, mit weiteren Trainingsrunden das Ergebnis weiter zu verbessern.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn man denkt, dass Ergebnis ist gut genug, dann kann man das Modell mit folgendem Befehl in eine Datei exportieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export('thug_cat_export.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modell verwenden um Vorhersagen zu machen\n",
    "\n",
    "Als Vorbereitung auf unsere WebApp mit der Sonnenbrille versuchen wir jetzt unser Modell mit Bildern aus dem Internet (die es hoffentlich nicht aus dem Training kennt):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -O test.jpg 'https://cdn.pixabay.com/photo/2014/03/29/09/17/cat-300572_1280.jpg'\n",
    "!wget -O test.jpg 'https://cdn.pixabay.com/photo/2015/01/31/12/36/cat-618470__480.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst laden wir das Bild und zeigen es an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img = open_image(\"test.jpg\")\n",
    "pred_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt erstellen wir einen neuen \"learner\" und laden die vorher exportierte \".pkl\" Datei:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_learner = load_learner(path, 'thug_cat_export.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit können wir jetzt eine Vorhersage machen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image_points, pred, out = test_learner.predict(pred_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die ImagePoints können wir wieder direkt verwenden, um sie mit Boardmitteln zu visualisieren - sie müssen aber von der Skalierung zu unserem Modell passen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativ gibt das Modell auch die \"raw\" Predictions aus. Diese sind sind in einem Werte-Bereich, den wir erst auf die Größe des getesteten Bildes umrechnen müssten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir also ein Bild mit einer anderen Größe als `size` verwenden, dann passen die Predictions scheinbar nicht:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img.show(y=predicted_image_points, figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skalieren wir aber das Bild wieder auf die beim Training verwendete `size`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_pred_img = pred_img.clone().resize((3, *size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_pred_img.show(y=predicted_image_points, figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... dann sieht das Ergebnis vielversprechend aus. Mit diesem Modell wollen wir Anschluss eine WebApp bereitstellen, die eine Sonnenbrille automatisch an die vorhergesagten Punkte der Augen platziert. Sinnvoller ist es natürlich die Bildpunkte entsprechend zu transformieren, so dass sie zu den Größenverhältnissen des Bildes passen. Das implementieren wir in der WebApp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referenzen\n",
    "\n",
    "Cat Dataset:\n",
    "\n",
    "Weiwei Zhang, Jian Sun, and Xiaoou Tang, Cat Head Detection - How to Effectively Exploit Shape and Texture Features, Proc. of European Conf. Computer Vision, vol. 4, pp.802-816, 2008.\n",
    "\n",
    "- fastai: https://www.fast.ai/\n",
    "- Kaggle: https://www.kaggle.com/\n",
    "- Bilder: https://pixabay.com/\n",
    "\n",
    "https://bootcamp.codecentric.ai/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
